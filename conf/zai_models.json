{
  "_README": {
    "description": "Model metadata for Z.ai when used via the Custom (OpenAI-compatible) provider.",
    "usage": "Use this manifest when you want to restrict Z.ai usage to the GLM-4.7/5.0 family only.",
    "example_env": [
      "CUSTOM_API_URL=https://api.z.ai/api/paas/v4/",
      "CUSTOM_API_KEY=your_zai_api_key_here",
      "CUSTOM_MODELS_CONFIG_PATH=/absolute/path/to/conf/zai_models.json",
      "CUSTOM_ALLOWED_MODELS=glm-5,glm-4.7,glm-4.7-flash,glm-4.7-flashx"
    ]
  },
  "models": [
    {
      "model_name": "glm-5",
      "friendly_name": "Z.ai (GLM-5)",
      "aliases": [
        "zai",
        "glm5",
        "glm-5-latest"
      ],
      "intelligence_score": 19,
      "description": "Z.ai GLM-5 (744B MoE, ~40B active). State-of-the-art on SWE-bench. Best for autonomous coding, complex system design, and long-horizon tasks requiring iterative self-correction.",
      "context_window": 200000,
      "max_output_tokens": 128000,
      "supports_extended_thinking": true,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_images": false,
      "supports_temperature": true
    },
    {
      "model_name": "glm-4.7",
      "friendly_name": "Z.ai (GLM-4.7)",
      "aliases": [
        "glm47",
        "glm-4.7-flagship"
      ],
      "intelligence_score": 18,
      "description": "Z.ai GLM-4.7 (355B MoE, 200K context). Highly efficient with exceptional tool-calling and reliability. Best for tool orchestration, long-document pipelines, and reliable agentic code generation.",
      "context_window": 200000,
      "max_output_tokens": 128000,
      "supports_extended_thinking": true,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_images": false,
      "supports_temperature": true
    },
    {
      "model_name": "glm-4.7-flashx",
      "friendly_name": "Z.ai (GLM-4.7-FlashX)",
      "aliases": [
        "flashx",
        "glm47-flashx",
        "glm-flashx"
      ],
      "intelligence_score": 13,
      "description": "Z.ai GLM-4.7-FlashX (OpenAI-compatible) - High-speed variant",
      "context_window": 200000,
      "max_output_tokens": 128000,
      "supports_extended_thinking": true,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_images": false,
      "supports_temperature": true
    },
    {
      "model_name": "glm-4.7-flash",
      "friendly_name": "Z.ai (GLM-4.7-Flash)",
      "aliases": [
        "glm47-flash",
        "glm-flash",
        "flash"
      ],
      "intelligence_score": 12,
      "description": "Z.ai GLM-4.7-Flash (OpenAI-compatible) - Fast 30B MoE model (59.2% SWE-bench)",
      "context_window": 200000,
      "max_output_tokens": 128000,
      "supports_extended_thinking": true,
      "supports_system_prompts": true,
      "supports_streaming": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_images": false,
      "supports_temperature": true
    }
  ]
}
